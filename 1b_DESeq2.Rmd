---
title: "RNAseq analysis of FAC-sorted ISC/EBs with LOF/GOF treatment for Sc/Da"
description: "DEG analysis based on DESeq2 and GSEA"
principal investigator: "Joaquín de Navascués"
researcher: "Aleix Puig, modified by Joaquín de Navascués"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: readable
    df_print: paged
---
```{r set-publication-theme, echo=FALSE, cache=FALSE}
ggplot2::theme_set(ggpubr::theme_pubr(base_size=10))
```

```{r setup, echo = FALSE, cache = FALSE}
knitr::opts_chunk$set(dev = c('png', 'cairo_pdf'), 
                      fig.align = 'center', fig.height = 5, fig.width = 8.5, 
                      pdf.options(encoding = "ISOLatin9.enc"),
                      fig.path='integration/figures/', warning=FALSE, message=FALSE)
```


# START FROM SCRATCH
# DGE ANALYSIS IS DONE WITH BATCH-CORRECTION BY DESEQ2 ALREADY
# DO BATCH-CORRECTION USING DESEQ2 ALONE, MAYBE (ONLY MAYBE) USE COMBATSEQ_CRRECTION AS INPUT INTO DESEQ2
# USE COMBATSEQ JUST FOR VISUALISATION IF POSSIBLE AND ONLY IF REALLY ADVANTAGEOUS OVER DESEQ2/LIMMA











# 1 Getting ready

We have five different conditions expressed with the _esg-Gal4_ driver, in two batches:

* Batch `a`:
  
  * _UAS-GFP_ (?) (control)
  * _UAS-daughterless_ (_da_)
  * _UAS-da^RNAi^_ (TRiP-line, either JF02488 or JF02092)
  
* Batch `b`:

  * _UAS-GFP_ (?) (control)
  * _UAS-da:da_
  * _UAS-scute_

The target cells were labelled with UAS-GFP and FAC-sorted, RNA extracted, reverse-transcribed, amplified and sequenced with Illumina.
Importantly, the first two have their own control, while the last two have a different one, as they were made separately.
In the first version of this script, I am doing two separate analyses, but because eventually I will need to show all the data together, batch-correction will be required, which is what I will do here.

```{r, echo=FALSE, warning=FALSE, results=FALSE}
# DGE analysis
library(DESeq2)          # to normalise RNAseq count data and perform DEG analysis
# general bioinformatics
library(edgeR)
library(biomaRt)         # to annotate the final gene list with common gene names
library(rtracklayer)     # to handling gene/exon coordinates data
library(GenomicFeatures) # to handling gene/exon coordinates data
# batch correction
library(sva) # >= v3.36.0
library(BatchQC)
library(preprocessCore)
# library(limma)
# plotting and data tidying
library(ggplot2)         # for making QC plots
library(dplyr)           # for handling data frames
library(stringr)         # for handling strings
library(pheatmap)        # to plot heatmap
library(gridExtra)
library(UpSetR)
library(ggthemes) # italics in the figures
library(ggtext) # italics in the figures
library(gridExtra)
# general convenience
library(here)
setwd(here())
```

TPM function (we'll need it later)
```{r}
tpm <- function(counts, lengths) {
  return ((counts * 1e6) / (lengths * sum(counts/lengths,na.rm=TRUE)))
}
```

#### Read genomic features from GTF file

Read the gene coordinates from the GTF file into an R data structure from resources.
Export the transcript lengths for all of the transcripts, from this object.
Use the unique() function to get a vector of all gene IDs.
Get the maximum transcript length for each gene. Maximum gene lengths are required for a gene‐length‐normalisation later in the script.

```{r include=FALSE, warning=FALSE}
txdb <- makeTxDbFromGRanges(import('resources/dmel-all-r6.50.gtf'))

allTranscripts <- transcriptLengths(txdb)

allGeneIDs <- unique(allTranscripts$gene_id)

allGeneLengths <- as.data.frame(allTranscripts %>%
  group_by(gene_id) %>%
  summarize(max.tx_len = max(tx_len)) )
```

#### Get the gene symbols

Genes are now identified as FlyBase IDs (e.g. FBgn0031208). To get the gene names:

```{r}
ensembl = useEnsembl(biomart = "ENSEMBL_MART_ENSEMBL",
                     dataset="dmelanogaster_gene_ensembl",
                     host = "https://oct2022.archive.ensembl.org") # update this to the latest: https://www.ensembl.org/Help/ArchiveRedirect
filters = listFilters(ensembl) # It defines filters in case you have a specific query
attributes = listAttributes(ensembl) #Defines the features that will be showed

dlist <- getBM(attributes=c('ensembl_gene_id', 'external_gene_name'), mart = ensembl)
rownames(dlist) <- dlist$ensembl_gene_id
dlist[1] <- NULL
write.table(dlist, file="resources/gene_names.txt", col.names=NA)
```

#### Load raw data

Read in featureCounts for all samples:
```{r}
targets <- read.table("resources/targets_batched.txt", header=TRUE, sep="\t")

rawData <- NULL
# each column of rawData will contain the reads per gene of a sample
for (sampleID in targets$sampleID) {
  if (file.exists( paste("input/dadasc/featurecounts/",
                         sampleID,
                         ".featurecount", sep="") )){
    fileContents <- read.table(paste("input/dadasc/featurecounts/",
                                       sampleID, ".featurecount", sep=""),
                                 sep="\t",
                                 header=T)
    } else {
      fileContents <- read.table(paste("input/daoekd/featurecounts/",
                                       sampleID, ".featurecount", sep=""),
                                 sep="\t",
                                 header=T)
      }
  rawData <- cbind(rawData, fileContents[,7])
}
```

Add column and row names to the rawData matrix
```{r}
colnames(rawData) <- paste(targets$Condition, targets$Replicate, targets$Batch, sep='_')
rownames(rawData) <- fileContents$Geneid
```

We want to remove genes with low counts _in these samples_, so we do:
```{r}
cpms <- cpm(rawData)
keep <- rowSums(cpms > 1) >= 3 # detected in at least 3 samples (out of 6, originally)
rawData <- rawData[keep,]
```

# 2 Batch correction with ComBat-seq

## 2A Using raw count data

Based on this tutorial:
https://rnabio.org/module-03-expression/0003/05/01/Batch-Correction/

Conditions, batches and replicates are all identified in `targets`.
Let us use PCA to visualise the similarity between samples:
```{r}
# calculate PC
pca_uncorrected_obj <- prcomp(rawData)
# pull PCA values from the object
pca_uncorrected <- as.data.frame(pca_uncorrected_obj[2]$rotation)
# assign labels
pca_uncorrected[,"condition"] <- targets$Condition
pca_uncorrected[,"batch"]     <- targets$Batch
pca_uncorrected[,"replicate"] <- targets$Replicate
# make plot
cols <- c("DaKD"="#1F78B4", "DaOE"="#FF7F00", "Control"="#6A3D9A", "DaDaOE"="#E31A1C" , "ScOE"="#33A02C")
xlab <- paste0("PC1, ",
               round(summary(pca_uncorrected_obj)$importance["Proportion of Variance","PC1"]*100, 1),
               " %")
ylab <- paste0("PC2, ",
               round(summary(pca_uncorrected_obj)$importance["Proportion of Variance","PC2"]*100, 1),
               " %")
title <- "PCA, *daugtherless* function RNA-seq analysis"
subtitle <- "**RAW, UNCORRECTED DATA**"
p1 <- ggplot(data=pca_uncorrected, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))
```

Perform batch correction:
```{r, echo=FALSE, results=FALSE}
# Transform the format of our groups and batches from names ("a", "b") to numbers (1, 2)
# in the command below "sapply" is used to apply the "switch" command to each element and convert names to numbers as we define
groups = sapply(as.character(targets$Condition), switch,
                "DaKD" = 1, "DaOE" = 2, "Control" = 3, "DaDaOE" = 4, "ScOE" = 5, USE.NAMES = F)
batches = sapply(as.character(targets$Batch), switch,
                 "a" = 1, "b" = 2, USE.NAMES = F)
# Run ComBat_seq
corrected_data = ComBat_seq(counts = as.matrix(rawData), batch = batches, group = groups)
# Join the gene IDs onto the now corrected counts from ComBat_seq
# corrected_data = cbind(Gene=rownames(rawData), corrected_data) # no need to do this and then this will become non-numeric
```

PCA of the corrected dataset:
```{r, fig.width=7, fig.height=3}
# calculate PC
pca_corrected_obj <- prcomp(corrected_data)
# pull PCA values from the object
pca_corrected <- as.data.frame(pca_corrected_obj[2]$rotation)
# assign labels
pca_corrected[,"condition"] <- targets$Condition
pca_corrected[,"batch"]     <- targets$Batch
pca_corrected[,"replicate"] <- targets$Replicate
# as above, create a PCA plot for comparison to the uncorrected data
xlab <- paste0("PC1, ",
               round(summary(pca_corrected_obj)$importance["Proportion of Variance","PC1"]*100, 1),
               " %")
ylab <- paste0("PC2, ",
               round(summary(pca_corrected_obj)$importance["Proportion of Variance","PC2"]*100, 1),
               " %")
subtitle <- "**RAW, BATCH-CORRECTED DATA**"
p2 <- ggplot(data=pca_corrected, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))
grid.arrange(p1, p2, ncol = 2)
```

This is not very helpful - the controls are still very far away. Maybe this would work better if DESeq2 had normalised the data first?

## 2B Using DESeq2-normalised data

Create experimental design object (mapping samples to conditions and batches)
```{r}
exptDesign = data.frame(
  row.names = colnames(rawData),
  condition = targets$Condition,
  batch = targets$Batch)
```

Create a DESeq2 object containing this experimental design.
```{r, warning=FALSE}
exptObject <- DESeqDataSetFromMatrix(countData = rawData,
                                     colData = exptDesign,
                                     design = ~ condition + batch)
exptObject$condition <- factor(exptObject$condition, levels = c("Control", "DaKD", "DaOE", "DaDaOE", "ScOE"))
```

Run the differential analysis. This will:

* normalise the data
* correct for dispersion (variance between replicates)
```{r}
analysisObject = DESeq(exptObject)
# Pull out the raw and normalised data from the analysis object.
rawCounts <- as.data.frame(counts(analysisObject, normalized=FALSE))
normalisedCounts <- as.data.frame(counts(analysisObject, normalized=TRUE))
```

Now let us compare PCAs of `rawCounts` and `normalisedCounts`:
```{r, fig.width=7, fig.height=6}
# Raw Uncorrected
pca_RU_obj <- prcomp(rawCounts)
pca_RU <- as.data.frame(pca_RU_obj[2]$rotation)
pca_RU[,"condition"] <- targets$Condition
pca_RU[,"batch"]     <- targets$Batch
pca_RU[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_RU_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_RU_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**RAW, UNCORRECTED DATA**"
q1 <- ggplot(data=pca_RU, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))
# Raw Corrected
corrawCounts = ComBat_seq(counts = as.matrix(rawCounts), batch = batches, group = groups)
pca_RC_obj <- prcomp(corrawCounts)
pca_RC <- as.data.frame(pca_RC_obj[2]$rotation)
pca_RC[,"condition"] <- targets$Condition
pca_RC[,"batch"]     <- targets$Batch
pca_RC[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_RU_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_RU_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**RAW, CORRECTED DATA**"
q2 <- ggplot(data=pca_RC, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))
# Normalised Uncorrected
pca_NU_obj <- prcomp(normalisedCounts)
pca_NU <- as.data.frame(pca_NU_obj[2]$rotation)
pca_NU[,"condition"] <- targets$Condition
pca_NU[,"batch"]     <- targets$Batch
pca_NU[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_NU_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_NU_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**NORMALISED, UNCORRECTED DATA**"
q3 <- ggplot(data=pca_NU, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))
# Normalised Corrected
corrnormCounts = ComBat_seq(counts = as.matrix(normalisedCounts), batch = batches, group = groups)
pca_NC_obj <- prcomp(corrnormCounts)
pca_NC <- as.data.frame(pca_NC_obj[2]$rotation)
pca_NC[,"condition"] <- targets$Condition
pca_NC[,"batch"]     <- targets$Batch
pca_NC[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_NC_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_NC_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**NORMALISED, CORRECTED DATA**"
q4 <- ggplot(data=pca_NC, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=3) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=12),
        plot.subtitle=element_markdown(size=9))

grid.arrange(q1, q2, q3, q4, ncol=2, nrow=2)
```
The top plots are identical to using the `rawData`, but those using the `normalisedCounts` are quite different, and most importantly, cluster the controls together.

# 3 Batch correction with BatchQC

The first thing we need is to have the expression values as `quantile normalized`:
```{r echo=FALSE, warning=FALSE, results=FALSE}
QrawCounts <- normalize.quantiles(as.matrix(rawCounts))
QnormalisedCounts <- normalize.quantiles(as.matrix(normalisedCounts))
```

Now we can use the interactive `batchQC` mode to see the effect of applying batch correction using ComBat or SVA on either normalised or raw data:
```{r echo=FALSE, warning=FALSE, results=FALSE}
batchQC(
        dat=QrawCounts,
        #dat=QnormalisedCounts,
        batch=targets$Batch,
        condition=targets$Condition,
        report_file="batchqc_report_raw.html",
        #report_file="batchqc_report_norm.html",
        report_dir=".",
        report_option_binary="111111111",
        view_report=TRUE,
        interactive=TRUE,
        batchqc_output=TRUE)
```

The results from applying `ComBat-seq` (or `sva` too) to the `QnormalisedCounts` are great, with controls from both batches collapsing into a single cluster.

Why is this different than what I get by applying `ComBat-seq` directly to the data?
Maybe I need to use the quantile-normalised data? (this is required for `BatchQC` but I did not do it for the DESeq2-normalised data)
However, if I try to get these outside the interactive environment of `BatchQC`, I can't:
```{r echo=FALSE, warning=FALSE, fig.width=7, fig.height=3}
# Quantile Normalised Uncorrected
pca_QNU_obj <- prcomp(QnormalisedCounts)
pca_QNU <- as.data.frame(pca_QNU_obj[2]$rotation)
pca_QNU[,"condition"] <- targets$Condition
pca_QNU[,"batch"]     <- targets$Batch
pca_QNU[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_QNU_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_QNU_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**Q-NORMALISED, UNCORRECTED DATA**"
r1 <- ggplot(data=pca_QNU, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=2) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=10),
        plot.subtitle=element_markdown(size=7))
# Normalised Corrected
corrQnormCounts = ComBat_seq(counts = as.matrix(QnormalisedCounts),
                             batch = batches, group = groups)
pca_QNC_obj <- prcomp(corrQnormCounts)
pca_QNC <- as.data.frame(pca_QNC_obj[2]$rotation)
pca_QNC[,"condition"] <- targets$Condition
pca_QNC[,"batch"]     <- targets$Batch
pca_QNC[,"replicate"] <- targets$Replicate
xlab <- paste0("PC1, ", round(summary(pca_QNC_obj)$importance["Proportion of Variance","PC1"]*100, 1), " %")
ylab <- paste0("PC2, ", round(summary(pca_QNC_obj)$importance["Proportion of Variance","PC2"]*100, 1), " %")
subtitle <- "**Q-NORMALISED, BATCH-CORRECTED DATA (COMBAT)**"
r2 <- ggplot(data=pca_QNC, aes(x=PC1, y=PC2, color=condition, shape=batch)) +
  geom_point(size=2) +
  labs(title=title, subtitle=subtitle, x=xlab, y=ylab) +
  scale_colour_manual(values = cols) +
  theme(legend.position="right",
        plot.title=element_markdown(size=10),
        plot.subtitle=element_markdown(size=7))

grid.arrange(r1, r2, ncol=2)
```

Maybe this is because the DESeq data was normalised with all the batches together?
It seems logical that the normalisation should be done separately (however, DESeq2 can deal with batches, so it does not look like this is essential)




let us see later how if we use this as the input for DESeq2, it may work better...


# 4 Batch correction with Surrogate Variable Analysis

```{r}
library(bladderbatch)
data(bladderdata)
library(pamr)
library(limma)
targets_trim <- targets[,c(1,4,5)]
names(targets_trim) <- c('sample', 'condition', 'batch')
rownames(targets_trim) <- names(normalisedCounts)
targets_trim$sample <- 1:nrow(targets_trim)
targets_trim <- targets_trim %>% mutate(
  batch=purrr::set_names(1:2, c('a', 'b'))[batch]
  )
# apply(normalisedCounts, 2, function(x) anyNA(x)) # checks there are no NAs in the dataframe.

```












































# 2 DGE analysis

## 2.1 _daughterless_ overexpression and knockdown

We are now ready to read‐in the sample descriptions for the gene expression analysis. 
We need to define our conditions in the context of the biological replicates we have.
The raw data is not ordered by grouping the different conditions, but by the name of the experiment.
Therefore when I upload the sample descriptions I have to order them.
Read this file into a data.frame.


#### Create a DESeq2 design matrix

To run DESeq2 (following the DeSEq2 analysis guide in bioconductor), we need to create an experimental design object (sample ID to treatment mapping).
```{r}
exptDesign = data.frame(
  row.names = colnames(rawData),
  condition = targets$Condition,
  batch = targets$Batch)
```

#### Create a DeSEQ2 experimental object

Build a DESeq2 object containing this experimental design and rawData.
```{r, warning=FALSE}
exptObject <- DESeqDataSetFromMatrix(countData = rawData,
                                     colData = exptDesign,
                                     # the functions will look at the last variable:
                                     # https://support.bioconductor.org/p/121408/
                                     design = ~ batch + condition) 

exptObject$condition <- factor(exptObject$condition, levels = c("Control", "DaKD", "DaOE", "DaDaOE", "ScOE"))
```

#### Batch correction

```{r}
# Transform the normalized counts 
vsd_Object <- vst(exptObject, blind=TRUE)
plotPCA(vsd_Object)
```

Remove batch effect and re-plot:
```{r}
assay(vsd_Object) <- limma::removeBatchEffect(assay(vsd_Object), vsd_Object$batch) # do this just for plotting
plotPCA(vsd_Object)
```

This makes better sense, though it seems that the effect of the KD is small and the batch effects are large enough that the controls can't group together.

#### Basic QC and DGE analysis
When performing quality assessment of our count data, we need to transform the normalized counts for better visualization of the variance for unsupervised clustering analyses. To assess the similarity of the samples using hierarchical heatmaps, transform the normalized counts and perform hierarchical clustering analysis.
```{r}
# Extract the matrix of transformed counts
vsd_mat_Object <- assay(vsd_Object)
# Compute the correlation values between samples
vsd_cor_Object <- cor(vsd_mat_Object) 
# Plot the heatmap
pheatmap(vsd_cor_Object, annotation = dplyr::select(exptDesign, condition),
         cluster_rows=FALSE, cluster_cols=FALSE)

# pheatmap(norm_OEsig[2:7], 
#     color = heat_colors, 
#     cluster_rows = T, 
#     show_rownames = F,
#     annotation = meta, 
#     border_color = NA, 
#     fontsize = 10, 
#     scale = "row", 
#     fontsize_row = 10, 
#     height = 20)
```

Run the differential analysis. This will normalise the data, correct for dispersion (variance between replicates) and set data up for a differential comparison of any 2 conditions.

After fitting the model in the previous exercise, let's explore the fit of our data to the negative binomial model by plotting the dispersion estimates using the plotDispEsts() function. Remember that the dispersion estimates are used to model the raw counts; if the dispersions don't follow the assumptions made by DESeq2, then the variation in the data could be poorly estimated and the DE results could be less accurate.

The assumptions DESeq2 makes are that the dispersions should generally decrease with increasing mean and that they should more or less follow the fitted line.

```{r}
plotDispEsts(analysisObject)
```


#### TPM values
Then generate TPM values, using tpm() function.
```{r}
rawDataWithLengths <- merge(allGeneLengths, rawCounts, by.x="gene_id", by.y="row.names", all=T)
rawCountData <- rawDataWithLengths[,colnames(rawCounts)]
rownames(rawCountData) <- rawDataWithLengths[,1]

tpmData <- NULL

for (colName in colnames(rawCountData)) {
    tpmData <- cbind(tpmData, tpm(rawDataWithLengths[,colName], rawDataWithLengths$max.tx_len))
}

tpmData <- as.data.frame(tpmData)
colnames(tpmData) <- colnames(rawCounts)
rownames(tpmData) <- rawDataWithLengths[,1]
tpmNormalisedCounts <- tpmData[match(rownames(rawCounts), rownames(tpmData)), ] # Q for Aleix: is this normalised data?????

if (!identical(rownames(rawCounts), rownames(normalisedCounts))) {
    stop()
}
if (!identical(rownames(tpmNormalisedCounts), rownames(normalisedCounts))) {
    stop()
}
saveRDS(tpmNormalisedCounts, 'batched_counts.RDS')
```

### 2.1.1 _da_ knock-down vs control

```{r}
conditionOne <- 'WT'
conditionTwo <- 'KD'
```

Select the relevant column from the counts object made previously.
Add the term “raw”, “norm” or “tpm” to each of the column headings to distinguish the column names.
```{r}
conditions_sampleIDs <- targets[targets$Condition %in% c(conditionOne, conditionTwo),]$sampleID
slimRawCounts           <- rawCounts           %>% select(all_of(conditions_sampleIDs))
slimNormalisedCounts    <- normalisedCounts    %>% select(all_of(conditions_sampleIDs))
slimTpmNormalisedCounts <- tpmNormalisedCounts %>% select(all_of(conditions_sampleIDs))

colnames(slimRawCounts)           <- paste("raw", conditions_sampleIDs, sep=".")
colnames(slimNormalisedCounts)    <- paste("norm", conditions_sampleIDs, sep=".")
colnames(slimTpmNormalisedCounts) <- paste("tpm", conditions_sampleIDs, sep=".")
```

Create the comparison between the 2 conditions.
Create a data.frame containing all the count and DEdata, and sorted by the pvalue column, with the most significant genes at the top of the data.frame.
```{r}
deData <- as.data.frame(results(analysisObject, contrast=c("condition", conditionOne, conditionTwo), pAdjustMethod="BH"))
finalData <- cbind(rownames(deData), slimRawCounts, slimNormalisedCounts, slimTpmNormalisedCounts, deData)
colnames(finalData)[1] <- "ensemblGeneID"
```

Sort data and give genes their names
```{r}
sortedFinalData <- finalData[order(finalData$pvalue), ] 
sortedFinalData_named <- merge(sortedFinalData, dlist, by=0)
sortedFinalData_named <- sortedFinalData_named[,-1]
```

Write this data to a file under output/
```{r}
write.table(sortedFinalData, file=paste("output/batched/differential_expression/", conditionOne, "_vs_", conditionTwo, ".txt", sep=""), row.names=F, sep="\t", quote=F)
saveRDS(sortedFinalData_named, paste(conditionOne, "_vs_", conditionTwo, ".RDS", sep="") )
```

Get significant genes, because we want to cluster on this behaviour
```{r}
significantGenes <- as.vector(unlist(subset(sortedFinalData_named, pvalue <= 0.05, select=c("ensemblGeneID"))))
sigTpmNormalisedCounts <- subset(tpmNormalisedCounts, rownames(tpmNormalisedCounts) %in% significantGenes)
```
